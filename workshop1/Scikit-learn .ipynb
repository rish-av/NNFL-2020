{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn Preprocessing\n",
    "\n",
    "The Scikit-learn library has many machine learning packages ready off the shelf. However, we would like to concentrate on data preprocessing techniques that are made easy with Scikit Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The two stage process\n",
    "Most scikit learn libraries have two stages - 1) Fit stage and 2) Transform or Predict stage\n",
    "\n",
    "### Fit\n",
    "In the fit stage, all parameters/statistics are computed.\n",
    "\n",
    "### Transform or Predict\n",
    "For data preprocessing, the second stage is the transform stage. Using the statistics calculated in the fit stage,\n",
    "we transform the data accordingly.\n",
    "\n",
    "For machine learning models, the second stage is the predict stage. Using the learned parameters of the model in the fit stage, we make predictions on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Continuous Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. 18.]\n",
      "[-1.  2.]\n"
     ]
    }
   ],
   "source": [
    "# The learned statistics from the fit stage\n",
    "print(scaler.data_max_)\n",
    "print(scaler.data_min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.  ]\n",
      " [0.25 0.25]\n",
      " [0.5  0.5 ]\n",
      " [1.   1.  ]]\n"
     ]
    }
   ],
   "source": [
    "# Using the learned statistics for min-max scaling\n",
    "print(scaler.transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.  ]\n",
      " [0.25 0.25]\n",
      " [0.5  0.5 ]\n",
      " [1.   1.  ]]\n"
     ]
    }
   ],
   "source": [
    "# We can also combine both the steps in one function call\n",
    "print(scaler.fit_transform(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization Scaling\n",
    "\n",
    "If `x` was the previous variable then after standardization it becomes (`x`- `mean`)/`sigma`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.125  9.   ]\n",
      "[ 0.546875 35.      ]\n"
     ]
    }
   ],
   "source": [
    "# The learned statistics from the fit stage\n",
    "print(scaler.mean_)\n",
    "print(scaler.var_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.18321596 -1.18321596]\n",
      " [-0.50709255 -0.50709255]\n",
      " [ 0.16903085  0.16903085]\n",
      " [ 1.52127766  1.52127766]]\n"
     ]
    }
   ],
   "source": [
    "# Using the learned statistics for min-max scaling\n",
    "print(scaler.transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.18321596 -1.18321596]\n",
      " [-0.50709255 -0.50709255]\n",
      " [ 0.16903085  0.16903085]\n",
      " [ 1.52127766  1.52127766]]\n"
     ]
    }
   ],
   "source": [
    "# We can also combine both the steps in one function call\n",
    "print(scaler.fit_transform(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Categorical Variables\n",
    "\n",
    "Categorical variables in a normal dataset may either be present as random integers or as strings. The LabelEncoder and OneHotEncoder package is great for their preprocessing. There are two steps to preprocess categorical variables.\n",
    "\n",
    "## Step 1 - Map categories to a Sequence of Increasing Numbers\n",
    "\n",
    "## Step 2 - Use this Sequence for a One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "\n",
    "## If Categorical Variables are Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type_num = [1,2,2,6,2,1,1,1,6,2,6,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_num = LabelEncoder()\n",
    "le_num.fit(data_type_num)\n",
    "le_num.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform : [0 1 1 2 1 0 0 0 2 1 2 2]\n",
      "Inverse Transform : [1 1 2 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "print(\"Transform : {}\".format(le_num.transform(data_type_num)))\n",
    "print(\"Inverse Transform : {}\".format(le_num.inverse_transform([0, 0, 1, 2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 2 1 0 0 0 2 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(le_num.fit_transform(data_type_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If Categorical Variables are Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type_str = [\"paris\", \"paris\", \"tokyo\", \"amsterdam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['amsterdam', 'paris', 'tokyo'], dtype='<U9')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_str = LabelEncoder()\n",
    "le_str.fit(data_type_str)\n",
    "le_str.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform : [1 1 2 0]\n",
      "Inverse Transform : ['tokyo' 'tokyo' 'paris']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "print(\"Transform : {}\".format(le_str.transform(data_type_str)))\n",
    "print(\"Inverse Transform : {}\".format( le_str.inverse_transform([2, 2, 1]) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(le_str.fit_transform(data_type_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 2\n",
    "\n",
    "After we get a sequence of numbers, it is important to represent this information as one-hot vectors. One of the reasons being that any machine learning model that is fed with this data must be able to differentiaite between a normal numerical variable and a categorical variable. An example of one hot encoding is given below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](one-hot-encoding.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_num = OneHotEncoder(sparse=False)\n",
    "one_hot_str = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass the output of the label encoder to one hot encoder\n",
    "data_num = np.expand_dims(le_num.fit_transform(data_type_num),axis=1)\n",
    "one_hot_num.fit_transform(data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass the output of the label encoder to one hot encoder\n",
    "data_str = np.expand_dims(le_str.fit_transform(data_type_str),axis=1)\n",
    "one_hot_num.fit_transform(data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
